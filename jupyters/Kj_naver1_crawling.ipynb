{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **크롤링**\n",
    "## **1 크롤링 수집함수 생성하기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Web Crawler 함수\n",
    "from urllib import parse\n",
    "from urllib import parse, request\n",
    "\n",
    "def crawler_naver(url):\n",
    "    browser = \"Mozilla/5.0 (X11; Linux i686) AppleWebKit/537.17 (KHTML, like Gecko) Chrome/24.0.1312.27 Safari/537.17\"\n",
    "    return request.urlopen(request.Request(url, headers = {'User-Agent':browser})).read().decode('utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 네이버 Shopping 수집결과\n",
    "from lxml.html import fromstring, tostring\n",
    "def navershop_finder(token_search):\n",
    "    query = {\n",
    "        'query' : token_search,\n",
    "        'frm' : 'NVSHATC',\n",
    "    } \n",
    "    url_query = parse.urlencode(query, encoding='UTF-8', doseq=True)\n",
    "    resp = crawler_naver(\"https://search.shopping.naver.com/search/all.nhn?\" + url_query)\n",
    "    resp_lxml = fromstring(resp)\n",
    "    try:\n",
    "        resp_lxml = resp_lxml.xpath('//*[@class=\"list_basis\"]')[0] # 검색결과 목록\n",
    "        resp_lxml = resp_lxml.xpath('.//li')                       # 개별 list\n",
    "        result = []\n",
    "        for _ in resp_lxml:\n",
    "            category = _.xpath('.//div[@class=\"basicList_depth__2QIie\"]//text()')\n",
    "            if category:\n",
    "                result.append(\">\".join(category))\n",
    "        return result\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "# **네이버 쇼핑 Categoty 수집기**\n",
    "\n",
    "## **1 네이버 쇼핑 카테고리 크롤링**\n",
    "제품의 목록단위 정보 수집하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = {}\n",
    "# from tqdm import tqdm\n",
    "# import time\n",
    "# from lxml.html import fromstring, tostring\n",
    "# for number in tqdm(range(11)):\n",
    "#     url = f\"https://search.shopping.naver.com/category/category/500000{number:02}\" # (0 ~ 10)\n",
    "#     resp = crawler_naver(url)\n",
    "#     resp_lxml_raw = fromstring(resp)\n",
    "#     text_key = resp_lxml_raw.xpath('//h2[contains(@class, \"category_tit\")]//text()')[0]\n",
    "#     result[text_key] = [_ for _ in resp_lxml_raw.xpath('//h3//text()') if _ != \"보기\"]\n",
    "#     time.sleep(1)\n",
    "\n",
    "# import pandas as pd\n",
    "# item_category = pd.DataFrame(dict([(k,pd.Series(v)) for k,v in result.items() ])).fillna('')\n",
    "# # item_category.T.to_csv('categoty_.csv', index=None)\n",
    "# item_category.to_csv('categoty_naver.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2 크롤링 결과값 활용하기**\n",
    "저장된 데이터를 활용하여 내용 분석하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "패션의류, 패션잡화, 화장품/미용, 디지털/가전, 가구/인테리어, 출산/육아, 식품, 스포츠/레저, 생활/건강, 여가/생활편의, 면세점\n",
      "total_length : 204 개\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dict_category = pd.read_csv('./data/categoty_naver.csv').to_dict(orient='list')\n",
    "dict_category = {k: [_ for _ in items if str(_) != 'nan']   for k, items in dict_category.items()}\n",
    "print(\", \".join(list(dict_category.keys())))\n",
    "\n",
    "# dict 제품 구분에서 item 내용만 추출하기\n",
    "item_values = []\n",
    "for _, v in dict_category.items():\n",
    "    item_values += v\n",
    "item_values = sorted(set(item_values))\n",
    "print(f\"total_length : {len(item_values)} 개\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "# **Item 내용을 카테고리에 적용하기**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1 마을로 아이템 목록 불러오기**\n",
    "수집 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable      Type    Data/Info\n",
      "-------------------------------\n",
      "item_values   list    n=204\n",
      "v             list    n=7\n"
     ]
    }
   ],
   "source": [
    "%whos | grep list & str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(930, 906)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "items = pd.read_csv('./data/maulo_items.csv', encoding=\"cp949\")[\"Title\"].to_list()\n",
    "items_set = []\n",
    "for _ in items:\n",
    "    _ = _.split('/')[0]\n",
    "    if _ not in items_set:\n",
    "        items_set.append(_)\n",
    "len(items), len(items_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2 네이버 쇼핑 검색**\n",
    "- **[각 품종별 계량단위](http://blog.daum.net/gun515/15507743)** \n",
    "- **[품종별 단위](http://blog.daum.net/_blog/BlogTypeView.do?blogid=0HlvU&articleno=8373563&_bloghome_menu=recenttext)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naver Shopping Get\n",
    "def naver_finder(items_set):\n",
    "    r\"\"\"Naver Shopping 에서 Item Category 결과추출함수\"\"\"\n",
    "    import numpy as np\n",
    "    from random import randint\n",
    "    from time import sleep\n",
    "    from tqdm import tqdm    \n",
    "    result, errors = {}, []\n",
    "    for token_search in tqdm(items_set):\n",
    "        sleep(0.1 * randint(5,10))\n",
    "        token_results = navershop_finder(token_search)\n",
    "\n",
    "        # 검색 결과가 있는경우\n",
    "        if token_results:\n",
    "            result_count  = {}\n",
    "            for _ in token_results:\n",
    "                if _ not in list(result_count.keys()): \n",
    "                    result_count[_] = 0\n",
    "                else: \n",
    "                    result_count[_] +=1\n",
    "\n",
    "            # 검색결과 1개의 분류만 있는경우\n",
    "            if len(list(result_count.keys())) == 1:\n",
    "                result[token_search] = list(result_count.keys())[0]\n",
    "            # 검색결과 2개만 발견된 경우 (짧은 분류기준 활용하기)\n",
    "            elif len(list(result_count.keys())) == 2:\n",
    "                list_temp = list(result_count.keys())\n",
    "                result[token_search] = list_temp[np.argmin([len(_) for _ in list_temp])]            \n",
    "            # 검색결과 여러개 발견시 갯수많은 1개 저장\n",
    "            else:\n",
    "                for _, v in result_count.items():\n",
    "                    if v == max(result_count.values()):\n",
    "                        result[token_search] = _\n",
    "        else: \n",
    "            # 검색 결과가 없는 경우\n",
    "            result[token_search] = ''\n",
    "            errors.append(token_search)\n",
    "    print('Error counts is {}. working is Done...'.format(len(errors)))\n",
    "    return result\n",
    "\n",
    "# Running the Finder Function\n",
    "# naver_finder(items_set[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3 결과 데이터 저장 및 활용하기**\n",
    "[pickle 과 zip 을 활용한 저장](https://wikidocs.net/8929)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle, gzip\n",
    "# with gzip.open('./data/mauloItemNaver.pickle', 'wb') as f:\n",
    "# with open('./data/mauloItemNaver.pickle', 'wb') as f:\n",
    "#     pickle.dump(result, f, pickle.HIGHEST_PROTOCOL)\n",
    "# print(\"saving is done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle, gzip\n",
    "# with open('./data/mauloItemNaver.pickle', 'rb') as f:\n",
    "#     items_maulo_category = pickle.load(f)\n",
    "# print(\"loading the date.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "# **추가 작업의 진행**\n",
    "\n",
    "## **1 Noun Tokenizer**\n",
    "식품 과 서비스 내용이 대부분\n",
    "1. 식품 내용은 기존의 Category 분류 알고리즘 활용하기\n",
    "1. 서비스는 Infomation Architecture 를 활용한 대분류 생성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from muyong.nlp import food_nouns\n",
    "# items_none = [_.strip() for _,v in items_maulo_category.items()  if v == '']\n",
    "# with open(\"data/food_nouns.txt\" , \"r\") as f:\n",
    "#     nouns_token = f.read().split(\",\")\n",
    "# menu_valid = [[\"_\".join(food_nouns(_, nouns_token)), _]  for _ in items_none]\n",
    "# pd.DataFrame(menu_valid).to_csv(\"items_error.csv\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2 Handwriting Fixed**\n",
    "알고리즘으로 해결 안되는 내용 추가작업 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle, gzip\n",
    "# with open('./data/mauloItemNaver.pickle', 'rb') as f:\n",
    "#     items_maulo_category = pickle.load(f)\n",
    "# print(\"loading the date.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'고기완자>>  곶감>>  구운마늘 치킨>>  균형영양식>>  금은방>>  김밥>>  김치돈육>>  김치참치>>  닭가슴살치즈>>  된장미역>>  디포리>>  떡갈비>>  매실장아찌>>  물냉면>>  미니버거>>  보리차>>  불고기야채>>  비빔냉면>>  삼계탕>>  상품권>>  상회>>  샌드위치>>  공간 서비스>>  교육 서비스>>  기타 서비스>>  돌보기 서비스>>  상품권 서비스>>  식사 서비스>>  의료 서비스>>  일자리 서비스>>  청소 서비스>>  행사 서비스>>  협동조합 서비스>>  홍보 서비스>>  회계 서비스>>  세탁조세정제>>  소고기들깨미역>>  소다짐육>>  손세정제>>  수제수세미>>  시래기>>  식초>>  쌀>>  안경점>>  야채>>  양배추_샌드위치>>  에그스크램블>>  에그후레이크>>  오색비빔밥>>  자전거>>  전복>>  전통차>>  젤리>>  참치>>  콘차우더>>  콩두부>>  크로켓>>  키위>>  해물야채>>  햄>>  헤어칼라크림>>  현미들깨>>  홍삼음료>>  흰살생선'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fixing the Error by Handwriting.\n",
    "import pandas as pd\n",
    "items_error_df = pd.read_csv('./data/maulo_items_error.csv', header=None)\n",
    "items_error = sorted(set(items_error_df[0].to_list()))\n",
    "result = []\n",
    "for _ in items_error:\n",
    "    if _.find(\"서비스\") != -1:\n",
    "        result.append(_.replace(\"서비스\", \"\").strip() + \" 서비스\")\n",
    "    else:\n",
    "        result.append(_)\n",
    "items_error = result\n",
    "\">>  \".join([_ for _ in items_error] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_error_token = naver_finder(items_error)\n",
    "# result = {}\n",
    "# for k,v in result_error_token.items():\n",
    "#     if k.find(\"서비스\") != -1:\n",
    "#         k = (\"서비스 \" + k.replace(\"서비스\", \"\").strip())\n",
    "#         result[k] = v\n",
    "#     else:\n",
    "#         result[k] = v\n",
    "# \"> \".join(result.keys())\n",
    "\n",
    "# import pickle\n",
    "# with open('./data/mauloItemNaver_error.pickle', 'wb') as f:\n",
    "#     pickle.dump(result, f, pickle.HIGHEST_PROTOCOL)\n",
    "# print(\"saving is done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3 ReRanging the Error Table**\n",
    "Handwriting Fixed Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading is done.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open('./data/mauloItemNaver_error.pickle', 'rb') as f:\n",
    "    dict_errors = pickle.load(f)\n",
    "print(\"loading is done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = {}\n",
    "for _ in range(len(items_error_df)):\n",
    "    result[items_error_df.iloc[_,1]] = dict_errors[items_error_df.iloc[_,0]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving is done.\n"
     ]
    }
   ],
   "source": [
    "# Saving the result\n",
    "with open('./data/mauloItemNaver_error_v1.pickle', 'wb') as f:\n",
    "    pickle.dump(result, f, pickle.HIGHEST_PROTOCOL)\n",
    "print(\"saving is done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4 Final Result**\n",
    "Merging the results.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading the date.\n"
     ]
    }
   ],
   "source": [
    "import pickle, gzip\n",
    "item_result = {}\n",
    "with open('./data/mauloItemNaver.pickle', 'rb') as f:\n",
    "    items_maulo_category = pickle.load(f)\n",
    "with open('./data/mauloItemNaver_error_v1.pickle', 'rb') as f:\n",
    "    items_maulo_category_error_fix_v1 = pickle.load(f)\n",
    "for k,v in items_maulo_category.items():\n",
    "    if v == \"\": \n",
    "        v = items_maulo_category_error_fix_v1[k.strip()]\n",
    "    else: \n",
    "        pass\n",
    "    if v == \"\": \n",
    "        print(k)\n",
    "    item_result[k.strip()] = v\n",
    "\n",
    "del items_maulo_category, items_maulo_category_error_fix_v1, k, v\n",
    "print(\"loading the date.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving is done.\n"
     ]
    }
   ],
   "source": [
    "# Saving the result\n",
    "with open('./data/category_Naver.pickle', 'wb') as f:\n",
    "    pickle.dump(item_result, f, pickle.HIGHEST_PROTOCOL)\n",
    "print(\"saving is done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
